# AUTOGENERATED FILE. Only edit for testing purposes, not for development. Generated from utils/unified_config.yaml. Generated by utils/split_config.py
Panel Config:
  id: 200
  title: System Speed-of-Light
  metrics_description:
    VALU FLOPs: 'The total floating-point operations executed per second on the VALU.
      This is also presented as a percent of the peak theoretical FLOPs achievable
      on the specific accelerator. Note: this does not include any floating-point
      operations from MFMA instructions.'
    VALU IOPs: 'The total integer operations executed per second on the VALU. This
      is also presented as a percent of the peak theoretical IOPs achievable on the
      specific accelerator. Note: this does not include any integer operations from
      MFMA instructions.'
    MFMA FLOPs (F8): The total number of 8-bit brain floating point MFMA operations
      executed per second. This does not include any 16-bit brain floating point operations
      from VALU instructions. This is also presented as a percent of the peak theoretical
      F8 MFMA operations achievable on the specific accelerator. It is supported on
      AMD Instinct MI300 series and later only.
    MFMA FLOPs (BF16): 'The total number of 16-bit brain floating point MFMA operations
      executed per second. Note: this does not include any 16-bit brain floating point
      operations from VALU instructions. This is also presented as a percent of the
      peak theoretical BF16 MFMA operations achievable on the specific accelerator.'
    MFMA FLOPs (F16): 'The total number of 16-bit floating point MFMA operations executed
      per second. Note: this does not include any 16-bit floating point operations
      from VALU instructions. This is also presented as a percent of the peak theoretical
      F16 MFMA operations achievable on the specific accelerator.'
    MFMA FLOPs (F32): 'The total number of 32-bit floating point MFMA operations executed
      per second. Note: this does not include any 32-bit floating point operations
      from VALU instructions. This is also presented as a percent of the peak theoretical
      F32 MFMA operations achievable on the specific accelerator.'
    MFMA FLOPs (F64): 'The total number of 64-bit floating point MFMA operations executed
      per second. Note: this does not include any 64-bit floating point operations
      from VALU instructions. This is also presented as a percent of the peak theoretical
      F64 MFMA operations achievable on the specific accelerator.'
    MFMA IOPs (Int8): 'The total number of 8-bit integer MFMA operations executed
      per second. Note: this does not include any 8-bit integer operations from VALU
      instructions. This is also presented as a percent of the peak theoretical INT8
      MFMA operations achievable on the specific accelerator.'
    Active CUs: Total number of active compute units (CUs) on the accelerator during
      the kernel execution.
    SALU Utilization: Indicates what percent of the kernel's duration the SALU was
      busy executing instructions. Computed as the ratio of the total number of cycles
      spent by the scheduler issuing SALU or SMEM instructions over the total CU cycles.
    VALU Utilization: Indicates what percent of the kernel's duration the VALU was
      busy executing instructions. Does not include VMEM operations. Computed as the
      ratio of the total number of cycles spent by the scheduler issuing VALU instructions
      over the total CU cycles.
    MFMA Utilization: Indicates what percent of the kernel's duration the MFMA unit
      was busy executing instructions. Computed as the ratio of the total number of
      cycles the MFMA was busy over the total CU cycles.
    VMEM Utilization: Indicates what percent of the kernel's duration the VMEM unit
      was busy executing instructions, including both global/generic and spill/scratch
      operations (see the VMEM instruction count metrics) for more detail). Does not
      include VALU operations. Computed as the ratio of the total number of cycles
      spent by the scheduler issuing VMEM instructions over the total CU cycles.
    Branch Utilization: Indicates what percent of the kernel's duration the branch
      unit was busy executing instructions. Computed as the ratio of the total number
      of cycles spent by the scheduler issuing branch instructions over the total
      CU cycles
    VALU Active Threads: Indicates the average level of divergence within a wavefront
      over the lifetime of the kernel. The number of work-items that were active in
      a wavefront during execution of each VALU instruction, time-averaged over all
      VALU instructions run on all wavefronts in the kernel.
    IPC: The ratio of the total number of instructions executed on the CU over the
      total active CU cycles. This is also presented as a percent of the peak theoretical
      bandwidth achievable on the specific accelerator.
    Wavefront Occupancy: 'The time-averaged number of wavefronts resident on the accelerator
      over the lifetime of the kernel. Note: this metric may be inaccurate for short-running
      kernels (less than 1ms). This is also presented as a percent of the peak theoretical
      occupancy achievable on the specific accelerator.'
    Theoretical LDS Bandwidth: Indicates the maximum amount of bytes that could have
      been loaded from, stored to, or atomically updated in the LDS per unit time
      (see LDS Bandwidth example for more detail). This is also presented as a percent
      of the peak theoretical F64 MFMA operations achievable on the specific accelerator.
    LDS Bank Conflicts/Access: The ratio of the number of cycles spent in the LDS
      scheduler due to bank conflicts (as determined by the conflict resolution hardware)
      to the base number of cycles that would be spent in the LDS scheduler in a completely
      uncontended case. This is also presented in normalized form (i.e., the Bank
      Conflict Rate).
    vL1D Cache Hit Rate: The ratio of the number of vL1D cache line requests that
      hit in vL1D cache over the total number of cache line requests to the vL1D cache
      RAM.
    vL1D Cache BW: The number of bytes looked up in the vL1D cache as a result of
      VMEM instructions per unit time. The number of bytes is calculated as the number
      of cache lines requested multiplied by the cache line size. This value does
      not consider partial requests, so e.g., if only a single value is requested
      in a cache line, the data movement will still be counted as a full cache line.
      This is also presented as a percent of the peak theoretical bandwidth achievable
      on the specific accelerator.
    L2 Cache Hit Rate: The ratio of the number of L2 cache line requests that hit
      in the L2 cache over the total number of incoming cache line requests to the
      L2 cache.
    L2 Cache BW: The number of bytes looked up in the L2 cache per unit time. The
      number of bytes is calculated as the number of cache lines requested multiplied
      by the cache line size. This value does not consider partial requests, so e.g.,
      if only a single value is requested in a cache line, the data movement will
      still be counted as a full cache line. This is also presented as a percent of
      the peak theoretical bandwidth achievable on the specific accelerator.
    L2-Fabric Read BW: "The number of bytes read by the L2 over the Infinity Fabric\u2122\
      \ interface per unit time. This is also presented as a percent of the peak theoretical\
      \ bandwidth achievable on the specific accelerator."
    L2-Fabric Write BW: The number of bytes sent by the L2 over the Infinity Fabric
      interface by write and atomic operations per unit time. This is also presented
      as a percent of the peak theoretical bandwidth achievable on the specific accelerator.
    L2-Fabric Read Latency: The time-averaged number of cycles read requests spent
      in Infinity Fabric before data was returned to the L2.
    L2-Fabric Write Latency: The time-averaged number of cycles write requests spent
      in Infinity Fabric before a completion acknowledgement was returned to the L2.
    sL1D Cache Hit Rate: The percent of sL1D requests that hit on a previously loaded
      line the cache. Calculated as the ratio of the number of sL1D requests that
      hit over the number of all sL1D requests.
    sL1D Cache BW: The number of bytes looked up in the sL1D cache per unit time.
      This is also presented as a percent of the peak theoretical bandwidth achievable
      on the specific accelerator.
    L1I Hit Rate: The number of bytes looked up in the L1I cache per unit time. This
      is also presented as a percent of the peak theoretical bandwidth achievable
      on the specific accelerator.
    L1I BW: The percent of L1I requests that hit on a previously loaded line the cache.
      Calculated as the ratio of the number of L1I requests that hit over the number
      of all L1I requests.
    L1I Fetch Latency: The average number of cycles spent to fetch instructions to
      a CU.
  data source:
  - metric_table:
      id: 201
      title: System Speed-of-Light
      header:
        metric: Metric
        value: Avg
        unit: Unit
        peak: Peak
        pop: Pct of Peak
      metric:
        VALU FLOPs:
          value: None
          unit: GFLOP/s
          peak: (((($max_sclk * $cu_per_gpu) * 64) * 2) / 1000)
          pop: None
        VALU IOPs:
          value: None
          unit: GIOP/s
          peak: (((($max_sclk * $cu_per_gpu) * 64) * 2) / 1000)
          pop: None
        MFMA FLOPs (BF16):
          value: None
          unit: GFLOP/s
          peak: ((($max_sclk * $cu_per_gpu) * 512) / 1000)
          pop: None
        MFMA FLOPs (F16):
          value: None
          unit: GFLOP/s
          peak: ((($max_sclk * $cu_per_gpu) * 1024) / 1000)
          pop: None
        MFMA FLOPs (F32):
          value: None
          unit: GFLOP/s
          peak: ((($max_sclk * $cu_per_gpu) * 256) / 1000)
          pop: None
        MFMA FLOPs (F64):
          value: None
          unit: GFLOP/s
          peak: ((($max_sclk * $cu_per_gpu) * 256) / 1000)
          pop: None
        MFMA IOPs (Int8):
          value: None
          unit: GIOP/s
          peak: ((($max_sclk * $cu_per_gpu) * 1024) / 1000)
          pop: None
        Active CUs:
          value: $numActiveCUs
          unit: CUs
          peak: $cu_per_gpu
          pop: ((100 * $numActiveCUs) / $cu_per_gpu)
        SALU Utilization:
          value: AVG(((100 * SQ_ACTIVE_INST_SCA) / ($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)))
          unit: pct
          peak: 100
          pop: AVG(((100 * SQ_ACTIVE_INST_SCA) / ($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)))
        VALU Utilization:
          value: AVG(((100 * SQ_ACTIVE_INST_VALU) / ($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)))
          unit: pct
          peak: 100
          pop: AVG(((100 * SQ_ACTIVE_INST_VALU) / ($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)))
        MFMA Utilization:
          value: None
          unit: pct
          peak: 100
          pop: None
        VMEM Utilization:
          value: None
          unit: pct
          peak: 100
          pop: None
        Branch Utilization:
          value: None
          unit: pct
          peak: 100
          pop: None
        VALU Active Threads:
          value: AVG(((SQ_THREAD_CYCLES_VALU / SQ_ACTIVE_INST_VALU) if (SQ_ACTIVE_INST_VALU
            != 0) else None))
          unit: Threads
          peak: $wave_size
          pop: (100 * AVG((SQ_THREAD_CYCLES_VALU / SQ_ACTIVE_INST_VALU / $wave_size)
            if (SQ_ACTIVE_INST_VALU != 0) else None))
        IPC:
          value: AVG((SQ_INSTS / SQ_BUSY_CU_CYCLES))
          unit: Instr/cycle
          peak: 5
          pop: ((100 * AVG((SQ_INSTS / SQ_BUSY_CU_CYCLES))) / 5)
        Wavefront Occupancy:
          value: AVG((SQ_ACCUM_PREV_HIRES / $GRBM_GUI_ACTIVE_PER_XCD))
          unit: Wavefronts
          peak: ($max_waves_per_cu * $cu_per_gpu)
          pop: (100 * AVG(((SQ_ACCUM_PREV_HIRES / $GRBM_GUI_ACTIVE_PER_XCD) / ($max_waves_per_cu
            * $cu_per_gpu))))
          coll_level: SQ_LEVEL_WAVES
        Theoretical LDS Bandwidth:
          value: AVG(((((SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT) * 4) * TO_INT($lds_banks_per_cu))
            / (End_Timestamp - Start_Timestamp)))
          unit: GB/s
          peak: (($max_sclk * $cu_per_gpu) * 0.128)
          pop: AVG((((((SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT) * 4) * TO_INT($lds_banks_per_cu))
            / (End_Timestamp - Start_Timestamp)) / (($max_sclk * $cu_per_gpu) * 0.00128)))
        LDS Bank Conflicts/Access:
          value: AVG(((SQ_LDS_BANK_CONFLICT / (SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT))
            if ((SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT) != 0) else None))
          unit: Conflicts/access
          peak: 32
          pop: ((100 * AVG(((SQ_LDS_BANK_CONFLICT / (SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT))
            if ((SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT) != 0) else None))) / 32)
        vL1D Cache Hit Rate:
          value: AVG(((100 - ((100 * (((TCP_TCC_READ_REQ_sum + TCP_TCC_WRITE_REQ_sum)
            + TCP_TCC_ATOMIC_WITH_RET_REQ_sum) + TCP_TCC_ATOMIC_WITHOUT_RET_REQ_sum))
            / TCP_TOTAL_CACHE_ACCESSES_sum)) if (TCP_TOTAL_CACHE_ACCESSES_sum != 0)
            else None))
          unit: pct
          peak: 100
          pop: AVG(((100 - ((100 * (((TCP_TCC_READ_REQ_sum + TCP_TCC_WRITE_REQ_sum)
            + TCP_TCC_ATOMIC_WITH_RET_REQ_sum) + TCP_TCC_ATOMIC_WITHOUT_RET_REQ_sum))
            / TCP_TOTAL_CACHE_ACCESSES_sum)) if (TCP_TOTAL_CACHE_ACCESSES_sum != 0)
            else None))
        vL1D Cache BW:
          value: AVG(((TCP_TOTAL_CACHE_ACCESSES_sum * 64) / (End_Timestamp - Start_Timestamp)))
          unit: GB/s
          peak: ((($max_sclk / 1000) * 64) * $cu_per_gpu)
          pop: ((100 * AVG(((TCP_TOTAL_CACHE_ACCESSES_sum * 64) / (End_Timestamp -
            Start_Timestamp)))) / ((($max_sclk / 1000) * 64) * $cu_per_gpu))
        L2 Cache Hit Rate:
          value: AVG((((100 * TCC_HIT_sum) / (TCC_HIT_sum + TCC_MISS_sum)) if ((TCC_HIT_sum
            + TCC_MISS_sum) != 0) else None))
          unit: pct
          peak: 100
          pop: AVG((((100 * TCC_HIT_sum) / (TCC_HIT_sum + TCC_MISS_sum)) if ((TCC_HIT_sum
            + TCC_MISS_sum) != 0) else None))
        L2 Cache BW:
          value: AVG(((TCC_REQ_sum * 64) / (End_Timestamp - Start_Timestamp)))
          unit: GB/s
          peak: ((($max_sclk / 1000) * 64) * TO_INT($total_l2_chan))
          pop: ((100 * AVG(((TCC_REQ_sum * 64) / (End_Timestamp - Start_Timestamp))))
            / ((($max_sclk / 1000) * 64) * TO_INT($total_l2_chan)))
        L2-Fabric Read BW:
          value: AVG((((TCC_EA_RDREQ_32B_sum * 32) + ((TCC_EA_RDREQ_sum - TCC_EA_RDREQ_32B_sum)
            * 64)) / (End_Timestamp - Start_Timestamp)))
          unit: GB/s
          peak: $hbmBandwidth
          pop: ((100 * AVG((((TCC_EA_RDREQ_32B_sum * 32) + ((TCC_EA_RDREQ_sum - TCC_EA_RDREQ_32B_sum)
            * 64)) / (End_Timestamp - Start_Timestamp)))) / $hbmBandwidth)
        L2-Fabric Write BW:
          value: AVG((((TCC_EA_WRREQ_64B_sum * 64) + ((TCC_EA_WRREQ_sum - TCC_EA_WRREQ_64B_sum)
            * 32)) / (End_Timestamp - Start_Timestamp)))
          unit: GB/s
          peak: $hbmBandwidth
          pop: ((100 * AVG((((TCC_EA_WRREQ_64B_sum * 64) + ((TCC_EA_WRREQ_sum - TCC_EA_WRREQ_64B_sum)
            * 32)) / (End_Timestamp - Start_Timestamp)))) / $hbmBandwidth)
        L2-Fabric Read Latency:
          value: AVG(((TCC_EA_RDREQ_LEVEL_sum / TCC_EA_RDREQ_sum) if (TCC_EA_RDREQ_sum
            != 0) else None))
          unit: Cycles
          peak: None
          pop: None
        L2-Fabric Write Latency:
          value: AVG(((TCC_EA_WRREQ_LEVEL_sum / TCC_EA_WRREQ_sum) if (TCC_EA_WRREQ_sum
            != 0) else None))
          unit: Cycles
          peak: None
          pop: None
        sL1D Cache Hit Rate:
          value: AVG((((100 * SQC_DCACHE_HITS) / (SQC_DCACHE_HITS + SQC_DCACHE_MISSES))
            if ((SQC_DCACHE_HITS + SQC_DCACHE_MISSES) != 0) else None))
          unit: pct
          peak: 100
          pop: AVG((((100 * SQC_DCACHE_HITS) / (SQC_DCACHE_HITS + SQC_DCACHE_MISSES))
            if ((SQC_DCACHE_HITS + SQC_DCACHE_MISSES) != 0) else None))
        sL1D Cache BW:
          value: AVG(((SQC_DCACHE_REQ / (End_Timestamp - Start_Timestamp)) * 64))
          unit: GB/s
          peak: ((($max_sclk / 1000) * 64) * $sqc_per_gpu)
          pop: ((100 * AVG(((SQC_DCACHE_REQ / (End_Timestamp - Start_Timestamp)) *
            64))) / ((($max_sclk / 1000) * 64) * $sqc_per_gpu))
        L1I Hit Rate:
          value: AVG(((100 * SQC_ICACHE_HITS) / (SQC_ICACHE_HITS + SQC_ICACHE_MISSES)))
          unit: pct
          peak: 100
          pop: AVG(((100 * SQC_ICACHE_HITS) / (SQC_ICACHE_HITS + SQC_ICACHE_MISSES)))
        L1I BW:
          value: AVG(((SQC_ICACHE_REQ / (End_Timestamp - Start_Timestamp)) * 64))
          unit: GB/s
          peak: ((($max_sclk / 1000) * 64) * $sqc_per_gpu)
          pop: ((100 * AVG(((SQC_ICACHE_REQ / (End_Timestamp - Start_Timestamp)) *
            64))) / ((($max_sclk / 1000) * 64) * $sqc_per_gpu))
        L1I Fetch Latency:
          value: AVG((SQ_ACCUM_PREV_HIRES / SQ_IFETCH))
          unit: Cycles
          peak: None
          pop: None
          coll_level: SQ_IFETCH_LEVEL
